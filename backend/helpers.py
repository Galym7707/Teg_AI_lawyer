# -*- coding: utf-8 -*-
import os
import re
import json
import logging
from typing import List, Dict, Tuple, Optional

import google.generativeai as genai
from rank_bm25 import BM25Okapi
import requests  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è web-–æ–±–æ–≥–∞—â–µ–Ω–∏—è

log = logging.getLogger(__name__)

# =========================
# HTML —Å–∞–Ω–∏—Ç–∞–π–∑–µ—Ä
# =========================
def sanitize_html(html: str) -> str:
    """
    –ß–∏—Å—Ç–∏–º —Ä–∞–∑–º–µ—Ç–∫—É –∏ –≤—ã—Ä–µ–∑–∞–µ–º –ª—é–±—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ ¬´–æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —é—Ä–∏—Å—Ç—É/–∞–¥–≤–æ–∫–∞—Ç—É/—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É¬ª.
    –¢–∞–∫–∂–µ —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å—ã –∏ –ø—É—Å—Ç—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã.
    """
    import re
    if not html:
        return ""

    h = html

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ –∏ –ø—É—Å—Ç—ã—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
    h = re.sub(r'(\r\n|\r)', '\n', h)
    h = re.sub(r'\n{3,}', '\n\n', h)
    h = re.sub(r'(<p>\s*</p>)+', '', h, flags=re.I)
    h = re.sub(r'(<br\s*/?>\s*){2,}', '<br>', h, flags=re.I)
    h = re.sub(r'<li>\s*<p>(.*?)</p>\s*</li>', r'<li>\1</li>', h, flags=re.I | re.S)
    h = re.sub(r'>\s+<', '><', h)

    # –ë–ê–ù: ¬´–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å/—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è/—Å–æ–≤–µ—Ç—É–µ–º ‚Ä¶ –∫ —é—Ä–∏—Å—Ç—É/–∞–¥–≤–æ–∫–∞—Ç—É/—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É¬ª
    banned = [
        r'–ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–π—Ç–µ—Å—å\s+—Å\s+—é—Ä–∏—Å—Ç[–∞-—è—ë]+',
        r'–æ–±—Ä–∞—Ç–∏—Ç[–µ—ë]—Å—å\s+–∫\s+(–∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω(–æ–º—É|—ã–º)\s+)?—é—Ä–∏—Å—Ç[–∞-—è—ë]+',
        r'–æ–±—Ä–∞—Ç–∏—Ç[–µ—ë]—Å—å\s+–∫\s+–∞–¥–≤–æ–∫–∞—Ç[–∞-—è—ë]+',
        r'–æ–±—Ä–∞—Ç–∏—Ç[–µ—ë]—Å—å\s+–∫\s+—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç[–∞-—è—ë]+',
        r'(—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è|—Å–æ–≤–µ—Ç—É—é|—Å–æ–≤–µ—Ç—É–µ–º)\s+–æ–±—Ä–∞—Ç–∏—Ç[–µ—ë]—Å—å\s+–∫\s+(–∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω(–æ–º—É|—ã–º)\s+)?—é—Ä–∏—Å—Ç[–∞-—è—ë]+',
        r'–ø–æ–ª—É—á–∏—Ç—å\s+–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏(—é|–∏)\s+—é—Ä–∏—Å—Ç[–∞-—è—ë]+',
        r'–¥–ª—è\s+—Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è\s+–∏—Å–∫–æ–≤(–æ–≥–æ|—ã—Ö)\s+–∑–∞—è–≤–ª–µ–Ω–∏[—è–π]\s+.*(—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è|–ª—É—á—à–µ)\s+–æ–±—Ä–∞—Ç–∏—Ç[–µ—ë]—Å—å\s+–∫\s+—é—Ä–∏—Å—Ç[–∞-—è—ë]+',
        r'–æ–±—Ä–∞–∑–µ—Ü\s+–∏—Å–∫–æ–≤–æ–≥–æ\s+–∑–∞—è–≤–ª–µ–Ω–∏—è\s+(–Ω–∞–π—Ç–∏\s+—Å–ª–æ–∂–Ω–æ|–º–æ–∂–Ω–æ\s+–Ω–∞–π—Ç–∏\s+–≤\s+–∏–Ω—Ç–µ—Ä–Ω–µ—Ç[–µ–∞])',
    ]
    replacement_main = (
        "–ï—Å–ª–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è —Å—É–¥–µ–±–Ω–∞—è –∑–∞—â–∏—Ç–∞, –ø–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –∏—Å–∫–æ–≤–æ–µ –∑–∞—è–≤–ª–µ–Ω–∏–µ –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –ì–ü–ö –†–ö. "
        "–ù–∏–∂–µ –¥–∞–Ω –±–∞–∑–æ–≤—ã–π –∫–∞—Ä–∫–∞—Å; –∞–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –ø–æ–¥ —Å–≤–æ—é —Å–∏—Ç—É–∞—Ü–∏—é."
    )
    for pat in banned:
        h = re.sub(pat, replacement_main, h, flags=re.I)

    # –ï—â—ë –æ–¥–∏–Ω –º—è–≥–∫–∏–π —Å–∏–Ω–æ–Ω–∏–º
    h = re.sub(r'–ø–æ–ª—É—á–∏—Ç—å\s+—é—Ä–∏–¥–∏—á–µ—Å–∫(—É—é|–∏–µ)\s+–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü(–∏—é|–∏–∏)[^.<]*\.', replacement_main + '.', h, flags=re.I)

    return h.strip()

# =========================
# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ—Ä–ø—É—Å–∞
# =========================
_WORD_RE = re.compile(r"[a-zA-Z–∞-—è–ê-–Ø—ë–Å0-9\-]+")

def _tok(s: str) -> List[str]:
    return _WORD_RE.findall((s or "").lower())

def _read_jsonl(path: str) -> List[Dict]:
    items = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            items.append(json.loads(line))
    return items

def load_laws_json(path: str) -> List[Dict]:
    if not os.path.isabs(path):
        base = os.path.dirname(os.path.abspath(__file__))
        path = os.path.join(base, path)
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def load_normalized_or_fallback() -> List[Dict]:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å laws/normalized.jsonl (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã).
    –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç ‚Äî —á–∏—Ç–∞–µ–º —Å—ã—Ä–æ–π kazakh_laws.json.
    """
    base = os.path.dirname(os.path.abspath(__file__))
    norm_path = os.path.join(base, "laws", "normalized.jsonl")
    if os.path.exists(norm_path):
        docs = _read_jsonl(norm_path)
        log.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º normalized.jsonl: %d —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤", len(docs))
        return docs

    raw_path = os.path.join(base, "laws", "kazakh_laws.json")
    raw = load_laws_json(raw_path)
    docs = []
    for x in raw:
        docs.append({
            "law_title": (x.get("title") or "").strip() or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è",
            "article_title": (x.get("title") or "").strip(),
            "source": x.get("source"),
            "plain_text": (x.get("text") or "").strip()
        })
    log.warning("‚ö†Ô∏è normalized.jsonl –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Ä–∞–±–æ—Ç–∞–µ–º –ø–æ —Å—ã—Ä–æ–º—É –∫–æ—Ä–ø—É—Å—É (%d –∑–∞–ø–∏—Å–µ–π)", len(docs))
    return docs

# =========================
# –ò–Ω–¥–µ–∫—Å BM25
# =========================
class LawIndex:
    def __init__(self, docs: List[Dict]):
        self.docs = docs
        corpus = []
        for d in docs:
            text = d.get("plain_summary") or d.get("plain_text") or ""
            corpus.append(_tok(text))
        self.bm25 = BM25Okapi(corpus)

    def search(self, query: str, top_k: int = 5) -> List[Tuple[Dict, float]]:
        q = _tok(query or "")
        if not q:
            return []
        scores = self.bm25.get_scores(q)
        idx_scores = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:top_k]
        return [(self.docs[i], float(s)) for i, s in idx_scores if s > 0.0]

def init_index() -> Tuple[List[Dict], LawIndex]:
    docs = load_normalized_or_fallback()
    return docs, LawIndex(docs)

# =========================
# –î–µ—Ç–µ–∫—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏–π
# =========================
_INTENT_PATTERNS = [
    ("resignation", r"\b(—É–≤–æ–ª–∏—Ç—å|—É–≤–æ–ª—å–Ω—è|—É–≤–æ–ª–∏—Ç—å—Å—è|—Ä–∞—Å—Ç–æ—Ä–≥–Ω—É—Ç—å\s+—Ç—Ä—É–¥|–∑–∞—è–≤–ª–µ–Ω–∏[–µ—è]\s+–æ–±\s+—É–≤–æ–ª–Ω)\b"),
    ("register_ip", r"\b(–æ—Ç–∫—Ä—ã—Ç—å\s+–∏–ø|—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü(–∏—è|–∏–∏)\s+–∏–ø|–∫–∞–∫\s+–æ—Ñ–æ—Ä–º–∏—Ç—å\s+–∏–ø|–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω(—ã–π|–æ–≥–æ)\s+–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª[—å—è])\b"),
    ("sick_leave", r"\b(–±–æ–ª—å–Ω–∏—á–Ω(—ã–π|–æ–≥–æ)|–ª–∏—Å—Ç\s+–Ω–µ—Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏)\b"),
    ("maternity", r"\b(–¥–µ–∫—Ä–µ—Ç|–ø–æ\s+—É—Ö–æ–¥—É\s+–∑–∞\s+—Ä–µ–±–µ–Ω–∫–æ–º|—Ä–æ–∂–¥–µ–Ω)\b"),
    ("vacation", r"\b(–æ—Ç–ø—É—Å–∫(–∞|–Ω—ã–µ)?|–Ω–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω(—ã–π|—ã–µ)\s+–æ—Ç–ø—É—Å–∫)\b"),
]

def detect_intent(question: str) -> str:
    q = (question or "").lower()
    for name, pat in _INTENT_PATTERNS:
        if re.search(pat, q):
            return name
    return "generic"

# =========================
# –®–∞–±–ª–æ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
# =========================
def _template_resignation() -> str:
    return (
        "<h3>–®–∞–±–ª–æ–Ω –∑–∞—è–≤–ª–µ–Ω–∏—è –æ–± —É–≤–æ–ª—å–Ω–µ–Ω–∏–∏ –ø–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º—É –∂–µ–ª–∞–Ω–∏—é</h3>"
        "<pre>"
        "–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—é ________________________________\n"
        "(–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏)\n\n"
        "–æ—Ç _________________________________________\n"
        "(–§–ò–û —Ä–∞–±–æ—Ç–Ω–∏–∫–∞, –¥–æ–ª–∂–Ω–æ—Å—Ç—å)\n\n"
        "–ó–ê–Ø–í–õ–ï–ù–ò–ï\n\n"
        "–ü—Ä–æ—à—É —É–≤–æ–ª–∏—Ç—å –º–µ–Ω—è –ø–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º—É –∂–µ–ª–∞–Ω–∏—é —Å ______________ 20__ –≥.\n"
        "–¢—Ä—É–¥–æ–≤–æ–π –¥–æ–≥–æ–≤–æ—Ä –æ—Ç __.__.20__ ‚Ññ ____ –ø—Ä–æ—à—É —Ä–∞—Å—Ç–æ—Ä–≥–Ω—É—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏\n"
        "—Ç—Ä—É–¥–æ–≤–æ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞.\n\n"
        "–° –ø–æ—Ä—è–¥–∫–æ–º —Ä–∞—Å—á—ë—Ç–∞ –∏ –ø–µ—Ä–µ–¥–∞—á–µ–π —Ç—Ä—É–¥–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ–∑–Ω–∞–∫–æ–º–ª–µ–Ω(–∞).\n\n"
        "¬´___¬ª__________20__ –≥.          _______________/____________/\n"
        "                                 (–ø–æ–¥–ø–∏—Å—å)       (–§–ò–û)\n"
        "</pre>"
    )

def _template_register_ip() -> str:
    return (
        "<h3>–®–∞–±–ª–æ–Ω –ø–µ—Ä–µ—á–Ω—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ò–ü</h3>"
        "<ul>"
        "<li><strong>–ò–ò–ù</strong>, –§–ò–û, –∞–¥—Ä–µ—Å —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏.</li>"
        "<li><strong>–í–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</strong> (–û–ö–≠–î).</li>"
        "<li><strong>–†–µ–∂–∏–º –Ω–∞–ª–æ–≥–æ–æ–±–ª–æ–∂–µ–Ω–∏—è</strong> (—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π/–ø–∞—Ç–µ–Ω—Ç/–ø—Ä–æ—á.).</li>"
        "<li><strong>–ö–æ–Ω—Ç–∞–∫—Ç—ã</strong> (—Ç–µ–ª–µ—Ñ–æ–Ω, email).</li>"
        "<li><strong>–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ —Ä–µ–∫–≤–∏–∑–∏—Ç—ã</strong> (–ø–æ—Å–ª–µ –æ—Ç–∫—Ä—ã—Ç–∏—è —Å—á—ë—Ç–∞).</li>"
        "</ul>"
        "<p>–ü–æ–¥–∞—á–∞ –∑–∞—è–≤–ª–µ–Ω–∏—è: –ø–æ—Ä—Ç–∞–ª eGov –∏–ª–∏ –¶–û–ù. –°—Ä–æ–∫: –æ–±—ã—á–Ω–æ 1 —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å.</p>"
    )

def template_for_intent(intent: str) -> str:
    if intent == "resignation":
        return _template_resignation()
    if intent == "register_ip":
        return _template_register_ip()
    return ""

# =========================
# –í–µ–±-–æ–±–æ–≥–∞—â–µ–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
# =========================
def web_enrich_official_sources(query: str, limit: int = 3) -> List[Dict]:
    """
    –ï—Å–ª–∏ –µ—Å—Ç—å SERPAPI_KEY (–∏–ª–∏ GOOGLE_API_KEY + GOOGLE_CSE_ID), –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º 1‚Äì3 —Å—Å—ã–ª–∫–∏
    —Å adilet.zan.kz / egov.kz / gov.kz. –ï—Å–ª–∏ –∫–ª—é—á–µ–π –Ω–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º [] –±–µ–∑ –æ—à–∏–±–æ–∫.
    """
    res: List[Dict] = []

    serp_key = os.getenv("SERPAPI_KEY")
    if serp_key:
        try:
            q = f"site:adilet.zan.kz OR site:egov.kz OR site:gov.kz {query}"
            r = requests.get(
                "https://serpapi.com/search.json",
                params={"engine": "google", "q": q, "num": limit, "hl": "ru", "gl": "kz", "api_key": serp_key},
                timeout=8,
            )
            j = r.json()
            for it in (j.get("organic_results") or [])[:limit]:
                res.append({"title": it.get("title"), "link": it.get("link"), "snippet": it.get("snippet")})
            return res
        except Exception as e:
            log.warning("SERPAPI failed: %s", e)

    g_key = os.getenv("GOOGLE_API_KEY")
    cse_id = os.getenv("GOOGLE_CSE_ID")
    if g_key and cse_id:
        try:
            q = f"{query} site:adilet.zan.kz OR site:egov.kz OR site:gov.kz"
            r = requests.get(
                "https://www.googleapis.com/customsearch/v1",
                params={"key": g_key, "cx": cse_id, "q": q, "num": limit, "hl": "ru"},
                timeout=8,
            )
            j = r.json()
            for it in (j.get("items") or [])[:limit]:
                res.append({"title": it.get("title"), "link": it.get("link"), "snippet": it.get("snippet")})
            return res
        except Exception as e:
            log.warning("Google CSE failed: %s", e)

    return res

# =========================
# Rule-based HTML (—Ñ–æ–ª–ª–±–µ–∫)
# =========================
def build_html_answer(question: str,
                      hits: List[Tuple[Dict, float]],
                      intent: str,
                      web_sources: Optional[List[Dict]] = None) -> str:
    parts: List[str] = []
    parts.append("<h3>–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞</h3>")

    if hits:
        parts.append("<p>–ù–∏–∂–µ ‚Äî –≤—ã–¥–µ—Ä–∂–∫–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É.</p>")
    else:
        parts.append("<p>–¢–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ –±–∞–∑–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü—Ä–∏–≤–æ–∂—É –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ —Ç–∏–ø–æ–≤–æ–π –ø—Ä–∞–∫—Ç–∏–∫–µ –†–ö.</p>")

    if hits:
        parts.append("<ul>")
        for rec, _ in hits[:5]:
            t = rec.get("article_title") or rec.get("law_title") or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
            src = rec.get("source") or ""
            if src:
                parts.append(f'<li><strong>{t}</strong> ‚Äî <a href="{src}" target="_blank">{src}</a></li>')
            else:
                parts.append(f"<li><strong>{t}</strong></li>")
        parts.append("</ul>")

    parts.append("<h3>–ß—Ç–æ –¥–µ–ª–∞—Ç—å –ø–æ—à–∞–≥–æ–≤–æ</h3>")
    if intent == "resignation":
        parts.append(
            "<ul>"
            "<li>–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –∑–∞—è–≤–ª–µ–Ω–∏–µ –æ–± —É–≤–æ–ª—å–Ω–µ–Ω–∏–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∞—Ç–æ–π.</li>"
            "<li>–ü–µ—Ä–µ–¥–∞–π—Ç–µ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—é –ø–æ–¥ –ø–æ–¥–ø–∏—Å—å / –≤ –∫–∞–Ω—Ü–µ–ª—è—Ä–∏—é ‚Äî –ø–æ–ª—É—á–∏—Ç–µ –æ—Ç–º–µ—Ç–∫—É –æ –ø—Ä–∏—ë–º–µ.</li>"
            "<li>–û—Ç—Ä–∞–±–æ—Ç–∞–π—Ç–µ —Å—Ä–æ–∫ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è (–æ–±—ã—á–Ω–æ 14 –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –¥–Ω–µ–π, –µ—Å–ª–∏ –Ω–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ –∏–Ω–æ–µ).</li>"
            "<li>–í –¥–µ–Ω—å —É–≤–æ–ª—å–Ω–µ–Ω–∏—è –ø–æ–ª—É—á–∏—Ç–µ —Ä–∞—Å—á—ë—Ç –∏ —Ç—Ä—É–¥–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.</li>"
            "</ul>"
        )
    elif intent == "register_ip":
        parts.append(
            "<ul>"
            "<li>–û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –≤–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–û–ö–≠–î) –∏ —Ä–µ–∂–∏–º –Ω–∞–ª–æ–≥–æ–æ–±–ª–æ–∂–µ–Ω–∏—è.</li>"
            "<li>–ü–æ–¥–∞–π—Ç–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –ø–æ—Ä—Ç–∞–ª eGov –∏–ª–∏ –≤ –¶–û–ù.</li>"
            "<li>–û—Ç–∫—Ä–æ–π—Ç–µ —Å—á—ë—Ç –≤ –±–∞–Ω–∫–µ, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –æ–Ω–ª–∞–π–Ω-–ö–ö–ú.</li>"
            "</ul>"
        )
    else:
        parts.append(
            "<ul>"
            "<li>–°–æ–±–µ—Ä–∏—Ç–µ —Ñ–∞–∫—Ç—ã –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–¥–∞—Ç—ã, —É—á–∞—Å—Ç–Ω–∏–∫–∏, –ø–µ—Ä–µ–ø–∏—Å–∫–∞, –¥–æ–≥–æ–≤–æ—Ä—ã).</li>"
            "<li>–ù–∞–π–¥–∏—Ç–µ –ø—Ä–∏–º–µ–Ω–∏–º—ã–µ –Ω–æ—Ä–º—ã –∏ –æ—Ñ–æ—Ä–º–∏—Ç–µ –∑–∞—è–≤–ª–µ–Ω–∏–µ/—Ö–æ–¥–∞—Ç–∞–π—Å—Ç–≤–æ –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –∑–∞–∫–æ–Ω–∞.</li>"
            "<li>–°–æ–±–ª—é–¥–∞–π—Ç–µ —Å—Ä–æ–∫–∏ –∏ –ø–æ—Ä—è–¥–æ–∫ –ø–æ–¥–∞—á–∏.</li>"
            "</ul>"
        )

    # –ë–ª–æ–∫ ¬´–ß—Ç–æ —É—Ç–æ—á–Ω–∏—Ç—å¬ª (–µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –æ–±—â–∏–π)
    if intent == "generic":
        parts.append(
            "<h3>–ß—Ç–æ —É—Ç–æ—á–Ω–∏—Ç—å</h3>"
            "<ul>"
            "<li>–ö—Ç–æ —É—á–∞—Å—Ç–Ω–∏–∫–∏ –∏ –∫–∞–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è (–¥–æ–≥–æ–≤–æ—Ä, —Ç—Ä—É–¥–æ–≤—ã–µ, —Å–µ–º–µ–π–Ω—ã–µ –∏ —Ç. –ø.).</li>"
            "<li>–ö–ª—é—á–µ–≤—ã–µ –¥–∞—Ç—ã –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã.</li>"
            "<li>–ö–∞–∫–∞—è —Ü–µ–ª—å: —Ä–∞—Å—Ç–æ—Ä–≥–Ω—É—Ç—å, –≤–∑—ã—Å–∫–∞—Ç—å, –æ–±–∂–∞–ª–æ–≤–∞—Ç—å –∏ –ø—Ä.</li>"
            "</ul>"
        )

    tpl = template_for_intent(intent)
    if tpl:
        parts.append(tpl)

    if web_sources:
        parts.append("<h3>–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏</h3><ul>")
        for s in web_sources:
            title = s.get("title") or s.get("link") or "–ò—Å—Ç–æ—á–Ω–∏–∫"
            link = s.get("link") or "#"
            parts.append(f'<li><a href="{link}" target="_blank">{title}</a></li>')
        parts.append("</ul>")

    return sanitize_html("\n".join(parts))

# =========================
# LLM (Gemini)
# =========================
def _init_llm():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        log.warning("GEMINI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî LLM –æ—Ç–∫–ª—é—á—ë–Ω.")
        return None
    try:
        genai.configure(api_key=api_key)
    except Exception as e:
        log.warning("Gemini configure failed: %s", e)
        return None

    model_name = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
    model = genai.GenerativeModel(
        model_name,
        generation_config={
            "temperature": float(os.getenv("LLM_TEMPERATURE", "0.1")),
            "max_output_tokens": int(os.getenv("LLM_MAX_TOKENS", "1400")),
        },
        system_instruction=(
            "–¢—ã ‚Äî –ò–ò-—é—Ä–∏—Å—Ç –ø–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω. "
            "–í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –°–¢–†–û–ì–û –≤ –ß–ò–°–¢–û–ú HTML (<p>, <ul>, <ol>, <li>, <strong>, <em>, <h3>, <a>), –±–µ–∑ Markdown.\n"
            "–ó–ê–ü–†–ï–©–ï–ù–û –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –≤—Ä–æ–¥–µ ¬´–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —é—Ä–∏—Å—Ç—É/–∞–¥–≤–æ–∫–∞—Ç—É/—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É¬ª "
            "–∏–ª–∏ ¬´–Ω–∞–π–¥–∏—Ç–µ –æ–±—Ä–∞–∑–µ—Ü –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ¬ª. –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –¥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —à–∞–≥–∏, —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–æ—Ä–º—ã –∏ –≥–æ—Ç–æ–≤—ã–µ —à–∞–±–ª–æ–Ω—ã.\n"
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞:\n"
            "1) <h3>–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞</h3> ‚Äî –ø–æ —Å—É—Ç–∏, –∫—Ä–∞—Ç–∫–æ.\n"
            "2) <h3>–ß—Ç–æ –¥–µ–ª–∞—Ç—å –ø–æ—à–∞–≥–æ–≤–æ</h3> ‚Äî 3‚Äì8 –∫–æ—Ä–æ—Ç–∫–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π.\n"
            "3) <h3>–ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –æ—Å–Ω–æ–≤–∞–Ω–∏—è</h3> ‚Äî –ø–µ—Ä–µ—á–∏—Å–ª–∏ –∞–∫—Ç—ã/—Å—Ç–∞—Ç—å–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.\n"
            "4) <h3>–®–∞–±–ª–æ–Ω—ã/–¥–æ–∫—É–º–µ–Ω—Ç—ã</h3> ‚Äî –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –°–ì–ï–ù–ï–†–ò–†–£–ô –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω –≤ <pre>‚Ä¶</pre>.\n"
            "5) –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –¥–æ–±–∞–≤—å –±–ª–æ–∫ <h3>–ß—Ç–æ —É—Ç–æ—á–Ω–∏—Ç—å</h3> —Å–æ —Å–ø–∏—Å–∫–æ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.\n"
        )
    )
    log.info("ü§ñ Gemini –≥–æ—Ç–æ–≤: %s", model_name)
    return model

_MODEL = _init_llm()

def call_llm(question: str,
             hits: List[Tuple[Dict, float]],
             intent: str,
             web_sources: Optional[List[Dict]] = None) -> str:
    if _MODEL is None:
        return ""

    # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π HTML-–∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∫–æ—Ä–ø—É—Å–∞
    ctx_parts: List[str] = []
    for rec, _ in hits[:3]:
        art = rec.get("article_title") or rec.get("law_title") or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
        src = rec.get("source") or ""
        txt = (rec.get("plain_summary") or rec.get("plain_text") or "").strip()
        if len(txt) > 1200:
            txt = txt[:1200] + "‚Ä¶"
        ctx_parts.append(f"<p><strong>{art}</strong>{(' ‚Äî ' + src) if src else ''}</p><p>{txt}</p>")

    # –ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø–æ–¥ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ
    template_hint = ""
    if intent == "resignation":
        template_hint = (
            "<p>–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —É–≤–æ–ª—å–Ω–µ–Ω–∏–µ ‚Äî –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–∫–ª—é—á–∏ –ø–æ–ª–Ω—ã–π —à–∞–±–ª–æ–Ω –∑–∞—è–≤–ª–µ–Ω–∏—è –æ–± —É–≤–æ–ª—å–Ω–µ–Ω–∏–∏ –≤ <pre>‚Ä¶</pre>.</p>"
        )
    elif intent == "register_ip":
        template_hint = (
            "<p>–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é –ò–ü ‚Äî –¥–∞–π —á–µ–∫-–ª–∏—Å—Ç –∏ —à–∞–±–ª–æ–Ω –ø–µ—Ä–µ—á–Ω—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–¥–∞—á–∏ —á–µ—Ä–µ–∑ eGov.</p>"
        )

    source_html = ""
    if web_sources:
        items = []
        for s in web_sources[:3]:
            title = s.get("title") or s.get("link")
            link = s.get("link")
            items.append(f'<li><a href="{link}" target="_blank">{title}</a></li>')
        if items:
            source_html = "<h3>–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–¥–ª—è —Å–ø—Ä–∞–≤–∫–∏)</h3><ul>" + "".join(items) + "</ul>"

    prompt = (
        "<h3>–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è</h3>"
        f"<p>{question}</p>"
        "<h3>–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤—ã–¥–µ—Ä–∂–∫–∏</h3>"
        + ("\n".join(ctx_parts) if ctx_parts else "<p>–¢–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.</p>")
        + template_hint
        + source_html
        + "<p>–°–æ–±–µ—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –≤ –ß–ò–°–¢–û–ú HTML –±–µ–∑ Markdown.</p>"
    )

    try:
        r = _MODEL.generate_content(prompt)
        txt = (r.text or "").strip()
        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –∑–∞–º–µ–Ω–∏–º **...** ‚Üí <strong>‚Ä¶</strong>
        txt = re.sub(r"\*\*(.+?)\*\*", r"<strong>\1</strong>", txt)
        txt = txt.replace("\n", "<br>")
        return sanitize_html(txt)
    except Exception as e:
        log.exception("LLM error: %s", e)
        return ""
    
# =========================
# –ü–æ–∏—Å–∫
# =========================
def search_laws(question: str, docs: List[Dict], index: LawIndex, top_k: int = 5):
    hits = index.search(question, top_k=top_k)
    intent = detect_intent(question)
    return hits, intent
